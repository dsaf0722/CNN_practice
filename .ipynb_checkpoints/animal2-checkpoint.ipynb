{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, GlobalAveragePooling2D , ZeroPadding2D,Convolution2D,BatchNormalization,Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "cpus = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "print(gpus, cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#資料增強\n",
    "train_img_gen = ImageDataGenerator(featurewise_center=True,\n",
    "                             featurewise_std_normalization=True,\n",
    "                             rotation_range=40,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=False,\n",
    "                             rescale=1./255,\n",
    "                             dtype=np.float32\n",
    "                            )\n",
    "\n",
    "test_img_gen = ImageDataGenerator(      \n",
    "                             rescale=1./255,\n",
    "                             dtype=np.float32\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ImageDataGenerator中常見的Augmentation(輸入形式、內容)：\n",
    "featurewise_center：輸入為Boolean(True or False)，以每一張feature map為單位將平均值設為0\n",
    "featurewise_std_normalization: 輸入為Boolean(True or False) ，以每一張feature map為單位將數值除以其標準差(上述兩步驟就是我們常見的Standardization)\n",
    "zca_whitening: Boolean，透過ZCA取出重要特徵(詳見：ZCA介紹)\n",
    "rotation_range：整數值，控制隨機旋轉角度\n",
    "width_shift_range：「浮點、整數、一維數」，圖像寬度上隨機偏移值\n",
    "height_shift_range：「浮點、整數、一維數」，圖像高度上隨機偏移值\n",
    "shear_range：浮點數，裁切範圍\n",
    "zoom_range：浮點數或範圍，隨機縮放比例\n",
    "horizontal_flip: Boolean，隨機水平翻轉\n",
    "vertical_flip:Boolean，隨機垂直翻轉\n",
    "rescale: 數值，縮放比例\n",
    "dtype：輸出資料型態\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224,224)\n",
    "batch_size = 8\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_img_gen.flow_from_directory(\n",
    "        \"C:../Desktop/animal/animal/cat_dog/train/\",\n",
    "        target_size=image_size,       # resize images to (224,224) to increase the training speed and efficiency\n",
    "        batch_size=batch_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_date shape: (8, 224, 224, 3)\n",
      "train_label shape: (8, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\hsiaoen\\venv\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "for train_data , train_label in train_generator:\n",
    "    print('train_date shape:', train_data.shape)\n",
    "    print('train_label shape:', train_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_img_gen.flow_from_directory(\n",
    "    \"C:../Desktop/animal/animal/cat_dog/test/\",\n",
    "     target_size=image_size,\n",
    "     batch_size=batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_data , test_label in train_generator:\n",
    "    print('test_date shape:', test_data.shape)\n",
    "    print('test_label shape:', test_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = 'same',activation = 'relu',input_shape = (224,224,3)))\n",
    "# model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 128,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters = 256,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# model.add(Conv2D(filters = 256,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
    "# model.add(Conv2D(filters = 256,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
    "# model.add(Conv2D(filters = 256,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv2D(filters = 512,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
    "# model.add(Conv2D(filters = 512,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
    "# model.add(Conv2D(filters = 512,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# model.add(Conv2D(filters = 512,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
    "# model.add(Conv2D(filters = 512,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
    "# model.add(Conv2D(filters = 512,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(256,activation = 'relu'))\n",
    "# model.add(Dense(64,activation = 'relu'))\n",
    "model.add(Dense(10,activation = 'softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                   steps_per_epoch = (10000//batch_size),\n",
    "                    epochs = epochs,\n",
    "                    validation_data = test_generator,\n",
    "                    validation_steps = (2000//batch_size)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('animal_classify.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainERR=history.history['loss']\n",
    "ValidERR=history.history['val_loss']\n",
    "TrainACC = history.history['accuracy']\n",
    "ValidACC = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1,epochs+1),TrainERR,'b',label='TrainERR')\n",
    "plt.plot(range(1,epochs+1),ValidERR,'r',label='ValidERR')\n",
    "plt.xlim([1,10])\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('error')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1,epochs+1),TrainACC,'b',label='TrainACC')\n",
    "plt.plot(range(1,epochs+1),ValidACC,'r',label='ValidACC')\n",
    "plt.xlim([1,10])\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.savefig('Learning_curve_animal_classify.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  keras.models.load_model('./animal_classify.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "img = image.load_img('D:animal/raw_img/raw/cat/ea34b5072afd003ed1584d05fb1d4e9fe777ead218ac104497f5c978a7eebdbb_640.jpg',target_size=(224,224,3))\n",
    "img = image.img_to_array(img)\n",
    "img = img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = model.predict(img.reshape(1,224,224,3))\n",
    "animal_list = ['butterfly', 'cat', 'chicken', 'cow', 'dog','elephant', 'horse', 'sheep', 'spider', 'squirrel']\n",
    "for i in range(10):\n",
    "    x = {str(animal_list[i]):proba[0][i]} \n",
    "    print(x)\n",
    "max_prob = round(proba[0].max(), 2)\n",
    "max_animal = animal_list[proba[0].argmax()]\n",
    "print(f'有 {max_prob} 這是一隻{max_animal}！')\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_path = '../../hsiaoen/Desktop/animal/animal/raw_img/'\n",
    "data_dir = pathlib.Path(dataset_path)\n",
    "image_count = len(list(data_dir.glob('*/*.jpeg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horses = list(data_dir.glob('horse/*'))\n",
    "PIL.Image.open(str(horses[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cow = list(data_dir.glob('cow/*'))\n",
    "PIL.Image.open(str(cow[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(['../Desktop/animal/animal/raw_img/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
